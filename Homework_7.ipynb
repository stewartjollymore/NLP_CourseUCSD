{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVZr+sbmNxoyETaHir3FQH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stewartjollymore/NLP_CourseUCSD/blob/main/Homework_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Stxwd5zqCwf_",
        "outputId": "7ac099da-1cae-4877-a2e0-e99c482d32b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "# At this stage Colab will try to access your Google Drive account.\n",
        "# Enter the password generated by Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"drive/My Drive/\")"
      ],
      "metadata": {
        "id": "JZL4rEY3EvK0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"GoogleNews-vectors-negative300.bin\"\n",
        "# Provide the complete path of the ‘GoogleNews’ file\n",
        "# stored in your Google Drive account.\n",
        "model = KeyedVectors.load_word2vec_format(path, binary=True, limit=200000)"
      ],
      "metadata": {
        "id": "Dz_S68P8DCft"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem #1"
      ],
      "metadata": {
        "id": "ehqaTvd9Gt4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vec1 = model[\"Marie_Curie\"] - model[\"physics\"] + model[\"politics\"]\n",
        "model.most_similar([vec1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDfbM4XhFdSj",
        "outputId": "cc4c5126-31d1-4a28-ceef-da37cfac35e0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Marie_Curie', 0.6391899585723877),\n",
              " ('politics', 0.45687681436538696),\n",
              " ('Sue_Ryder', 0.4075208604335785),\n",
              " ('Breakthrough_Breast_Cancer', 0.37573352456092834),\n",
              " ('Margaret_Thatcher', 0.3684638738632202),\n",
              " ('Marie_Curie_Cancer', 0.3580324947834015),\n",
              " ('politicians', 0.34992516040802),\n",
              " ('Breast_Cancer_Care', 0.34824055433273315),\n",
              " ('Mrs_Thatcher', 0.3457459509372711),\n",
              " ('politicans', 0.3389205038547516)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec2 = model[\"Cowboys\"] - model[\"Dallas\"] + model[\"Miami\"]\n",
        "model.most_similar([vec2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_alUHAlGH7X",
        "outputId": "2b5d9bd3-7eb0-4702-d0e3-17fd8429c78a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Cowboys', 0.7327904105186462),\n",
              " ('Dolphins', 0.7073556780815125),\n",
              " ('Miami_Dolphins', 0.6461875438690186),\n",
              " ('Broncos', 0.6419293284416199),\n",
              " ('Seminoles', 0.6188381910324097),\n",
              " ('Gators', 0.6109528541564941),\n",
              " ('Hokies', 0.592700719833374),\n",
              " ('Dallas_Cowboys', 0.5866430997848511),\n",
              " ('Sooners', 0.586640477180481),\n",
              " ('Cleveland_Browns', 0.5844414234161377)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec3 = model[\"Sacramento\"] - model[\"California\"] + model[\"Colorado\"]\n",
        "model.most_similar([vec3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odmLkq_ZGXwI",
        "outputId": "f54cf264-431f-4307-99ac-c39101089517"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Denver', 0.7687566876411438),\n",
              " ('Colorado', 0.7621335983276367),\n",
              " ('Sacramento', 0.7206397652626038),\n",
              " ('Grand_Junction', 0.6696534752845764),\n",
              " ('Fort_Collins', 0.6669073104858398),\n",
              " ('Boulder', 0.6501880288124084),\n",
              " ('Colorado_Springs', 0.6477945446968079),\n",
              " ('Pueblo', 0.6256301403045654),\n",
              " ('Spokane', 0.6246552467346191),\n",
              " ('Gunnison', 0.6222272515296936)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec4 = model[\"Cowboys\"] - model[\"Dallas\"] + model[\"San_Francisco\"]\n",
        "model.most_similar([vec4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVxeH6E5GjJd",
        "outputId": "20bbdcd1-4ea8-4620-ab66-5517d7c7329e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Cowboys', 0.71146559715271),\n",
              " ('Giants', 0.6826241612434387),\n",
              " ('Niners', 0.6466032266616821),\n",
              " ('##ers', 0.643872857093811),\n",
              " ('San_Francisco_##ers', 0.6088259816169739),\n",
              " ('Oakland_Raiders', 0.6043734550476074),\n",
              " ('Broncos', 0.5943415760993958),\n",
              " ('Raiders', 0.5565467476844788),\n",
              " ('Seahawks', 0.5484771728515625),\n",
              " ('Dallas_Cowboys', 0.5368008017539978)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem #2"
      ],
      "metadata": {
        "id": "3-x_FCzpHdvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "words1 = ['beautiful', \"gorgeous\", \"dazzling\", \"splendid\", \"magnificent\", \"ugly\"]\n",
        "words1_vec = model[words1]\n",
        "\n",
        "\n",
        "simMatrix = cosine_similarity(words1_vec, words1_vec)\n",
        "print(\"The cosine similarity between beautiful and gorgeous is\", simMatrix[0][1])\n",
        "print()\n",
        "print(\"The cosine similarity between beautiful and dazzling is\", simMatrix[0][2])\n",
        "print()\n",
        "print(\"The cosine similarity between beautiful and splendid is\", simMatrix[0][3])\n",
        "print()\n",
        "print(\"The cosine similarity between beautiful and magnificent is\", simMatrix[0][4])\n",
        "print()\n",
        "print(\"The cosine similarity between beautiful and ugly is\", simMatrix[0][5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LyDCIFDHdPg",
        "outputId": "ab58e6fe-6afb-49aa-a742-4ce5e7d4257e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cosine similarity between beautiful and gorgeous is 0.8353003\n",
            "\n",
            "The cosine similarity between beautiful and dazzling is 0.47949678\n",
            "\n",
            "The cosine similarity between beautiful and splendid is 0.5533437\n",
            "\n",
            "The cosine similarity between beautiful and magnificent is 0.65914047\n",
            "\n",
            "The cosine similarity between beautiful and ugly is 0.3344436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem #3"
      ],
      "metadata": {
        "id": "EMqDvFxAJu8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "words2 = [\"False\", \"fake\", \"fraudulent\", \"counterfeit\", \"spurious\", \"true\"]\n",
        "words2_vec = model[words2]\n",
        "\n",
        "\n",
        "simMatrix2 = cosine_similarity(words2_vec, words2_vec)\n",
        "(simMatrix2.sum(1)-1)/(simMatrix2.shape[1]-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VqmF6-DJw0n",
        "outputId": "da0ff1e1-3dd9-46d9-91d5-690a1e9d216a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.3181141 , 0.45435843, 0.40518808, 0.36029965, 0.366558  ,\n",
              "       0.24273667], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above I computed the average cosine similarity between all the words, then took the average across each row (*since this is a symetirc matrix you could do rows or columns*) ignoring the diagnoal (since they are NOT all 1 there is added noise) thereby accounting only for the similarites of the **OTHER** words.  I say the **true** does not belong, though it could be argued that there are a few differing clusters of these words given the averages are not that high."
      ],
      "metadata": {
        "id": "34uK5LgNLRoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem #4"
      ],
      "metadata": {
        "id": "wODb2byfMpMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "embed = hub.load(\"https://tfhub.dev/google/Wiki-words-250-with-normalization/2\")"
      ],
      "metadata": {
        "id": "04VzB_r1Mq-w"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words4 = [\"Coke\", \"Pepsi\", \"7Up\", \"Sprite\", \"Coca-Cola\"]\n",
        "words4_vec = embed(words4)\n",
        "\n",
        "simMatrix3 = cosine_similarity(words4_vec, words4_vec)\n",
        "simMatrix3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LloXra0gN_-v",
        "outputId": "121d2d5e-1271-4c3d-d4eb-098a0a012432"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99999976, 0.62521577, 0.5146611 , 0.50170887, 0.64903426],\n",
              "       [0.62521577, 1.0000001 , 0.6818692 , 0.63720137, 0.893294  ],\n",
              "       [0.5146611 , 0.6818692 , 1.0000001 , 0.5885447 , 0.7191731 ],\n",
              "       [0.50170887, 0.63720137, 0.5885447 , 0.9999998 , 0.6301661 ],\n",
              "       [0.64903426, 0.893294  , 0.7191731 , 0.6301661 , 0.9999999 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above you will see I did add some other non-cola soda brand names in there to see what the reults might be. I found it interesting the Sprite is moresimilar to Pepsi than it is to Coke but closer to Coca-Cola than Coke (Coca-Cola is the producer of Sprite).  Pretty interesting stuff here."
      ],
      "metadata": {
        "id": "m57Q1bHbOqMC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem #5"
      ],
      "metadata": {
        "id": "5MNvQuynPYj5"
      }
    }
  ]
}