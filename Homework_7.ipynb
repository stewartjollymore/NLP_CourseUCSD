{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNp5dmqhn7QBF8/92NsyP6m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stewartjollymore/NLP_CourseUCSD/blob/main/Homework_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Stxwd5zqCwf_",
        "outputId": "7ac099da-1cae-4877-a2e0-e99c482d32b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "# At this stage Colab will try to access your Google Drive account.\n",
        "# Enter the password generated by Google Drive.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"drive/My Drive/\")"
      ],
      "metadata": {
        "id": "JZL4rEY3EvK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"GoogleNews-vectors-negative300.bin\"\n",
        "# Provide the complete path of the ‘GoogleNews’ file\n",
        "# stored in your Google Drive account.\n",
        "model = KeyedVectors.load_word2vec_format(path, binary=True, limit=200000)"
      ],
      "metadata": {
        "id": "Dz_S68P8DCft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem #1"
      ],
      "metadata": {
        "id": "ehqaTvd9Gt4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vec1 = model[\"Marie_Curie\"] - model[\"physics\"] + model[\"politics\"]\n",
        "model.most_similar([vec1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IDfbM4XhFdSj",
        "outputId": "cc4c5126-31d1-4a28-ceef-da37cfac35e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Marie_Curie', 0.6391899585723877),\n",
              " ('politics', 0.45687681436538696),\n",
              " ('Sue_Ryder', 0.4075208604335785),\n",
              " ('Breakthrough_Breast_Cancer', 0.37573352456092834),\n",
              " ('Margaret_Thatcher', 0.3684638738632202),\n",
              " ('Marie_Curie_Cancer', 0.3580324947834015),\n",
              " ('politicians', 0.34992516040802),\n",
              " ('Breast_Cancer_Care', 0.34824055433273315),\n",
              " ('Mrs_Thatcher', 0.3457459509372711),\n",
              " ('politicans', 0.3389205038547516)]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec2 = model[\"Cowboys\"] - model[\"Dallas\"] + model[\"Miami\"]\n",
        "model.most_similar([vec2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_alUHAlGH7X",
        "outputId": "2b5d9bd3-7eb0-4702-d0e3-17fd8429c78a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Cowboys', 0.7327904105186462),\n",
              " ('Dolphins', 0.7073556780815125),\n",
              " ('Miami_Dolphins', 0.6461875438690186),\n",
              " ('Broncos', 0.6419293284416199),\n",
              " ('Seminoles', 0.6188381910324097),\n",
              " ('Gators', 0.6109528541564941),\n",
              " ('Hokies', 0.592700719833374),\n",
              " ('Dallas_Cowboys', 0.5866430997848511),\n",
              " ('Sooners', 0.586640477180481),\n",
              " ('Cleveland_Browns', 0.5844414234161377)]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec3 = model[\"Sacramento\"] - model[\"California\"] + model[\"Colorado\"]\n",
        "model.most_similar([vec3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odmLkq_ZGXwI",
        "outputId": "f54cf264-431f-4307-99ac-c39101089517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Denver', 0.7687566876411438),\n",
              " ('Colorado', 0.7621335983276367),\n",
              " ('Sacramento', 0.7206397652626038),\n",
              " ('Grand_Junction', 0.6696534752845764),\n",
              " ('Fort_Collins', 0.6669073104858398),\n",
              " ('Boulder', 0.6501880288124084),\n",
              " ('Colorado_Springs', 0.6477945446968079),\n",
              " ('Pueblo', 0.6256301403045654),\n",
              " ('Spokane', 0.6246552467346191),\n",
              " ('Gunnison', 0.6222272515296936)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec4 = model[\"Cowboys\"] - model[\"Dallas\"] + model[\"San_Francisco\"]\n",
        "model.most_similar([vec4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TVxeH6E5GjJd",
        "outputId": "20bbdcd1-4ea8-4620-ab66-5517d7c7329e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Cowboys', 0.71146559715271),\n",
              " ('Giants', 0.6826241612434387),\n",
              " ('Niners', 0.6466032266616821),\n",
              " ('##ers', 0.643872857093811),\n",
              " ('San_Francisco_##ers', 0.6088259816169739),\n",
              " ('Oakland_Raiders', 0.6043734550476074),\n",
              " ('Broncos', 0.5943415760993958),\n",
              " ('Raiders', 0.5565467476844788),\n",
              " ('Seahawks', 0.5484771728515625),\n",
              " ('Dallas_Cowboys', 0.5368008017539978)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem #2"
      ],
      "metadata": {
        "id": "3-x_FCzpHdvM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "words1 = ['beautiful', \"gorgeous\", \"dazzling\", \"splendid\", \"magnificent\", \"ugly\"]\n",
        "words1_vec = model[words1]\n",
        "\n",
        "\n",
        "simMatrix = cosine_similarity(words1_vec, words1_vec)\n",
        "print(\"The cosine similarity between beautiful and gorgeous is\", simMatrix[0][1])\n",
        "print()\n",
        "print(\"The cosine similarity between beautiful and dazzling is\", simMatrix[0][2])\n",
        "print()\n",
        "print(\"The cosine similarity between beautiful and splendid is\", simMatrix[0][3])\n",
        "print()\n",
        "print(\"The cosine similarity between beautiful and magnificent is\", simMatrix[0][4])\n",
        "print()\n",
        "print(\"The cosine similarity between beautiful and ugly is\", simMatrix[0][5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LyDCIFDHdPg",
        "outputId": "ab58e6fe-6afb-49aa-a742-4ce5e7d4257e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cosine similarity between beautiful and gorgeous is 0.8353003\n",
            "\n",
            "The cosine similarity between beautiful and dazzling is 0.47949678\n",
            "\n",
            "The cosine similarity between beautiful and splendid is 0.5533437\n",
            "\n",
            "The cosine similarity between beautiful and magnificent is 0.65914047\n",
            "\n",
            "The cosine similarity between beautiful and ugly is 0.3344436\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem #3"
      ],
      "metadata": {
        "id": "EMqDvFxAJu8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "words2 = [\"False\", \"fake\", \"fraudulent\", \"counterfeit\", \"spurious\", \"true\"]\n",
        "words2_vec = model[words2]\n",
        "\n",
        "\n",
        "simMatrix2 = cosine_similarity(words2_vec, words2_vec)\n",
        "(simMatrix2.sum(1)-1)/(simMatrix2.shape[1]-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VqmF6-DJw0n",
        "outputId": "da0ff1e1-3dd9-46d9-91d5-690a1e9d216a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.3181141 , 0.45435843, 0.40518808, 0.36029965, 0.366558  ,\n",
              "       0.24273667], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above I computed the average cosine similarity between all the words, then took the average across each row (*since this is a symetirc matrix you could do rows or columns*) ignoring the diagnoal (since they are NOT all 1 there is added noise) thereby accounting only for the similarites of the **OTHER** words.  I say the **true** does not belong, though it could be argued that there are a few differing clusters of these words given the averages are not that high."
      ],
      "metadata": {
        "id": "34uK5LgNLRoA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem #4"
      ],
      "metadata": {
        "id": "wODb2byfMpMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import numpy as np\n",
        "embed = hub.load(\"https://tfhub.dev/google/Wiki-words-250-with-normalization/2\")"
      ],
      "metadata": {
        "id": "04VzB_r1Mq-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words4 = [\"Coke\", \"Pepsi\", \"7Up\", \"Sprite\", \"Coca-Cola\"]\n",
        "words4_vec = embed(words4)\n",
        "\n",
        "simMatrix3 = cosine_similarity(words4_vec, words4_vec)\n",
        "simMatrix3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LloXra0gN_-v",
        "outputId": "121d2d5e-1271-4c3d-d4eb-098a0a012432"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.99999976, 0.62521577, 0.5146611 , 0.50170887, 0.64903426],\n",
              "       [0.62521577, 1.0000001 , 0.6818692 , 0.63720137, 0.893294  ],\n",
              "       [0.5146611 , 0.6818692 , 1.0000001 , 0.5885447 , 0.7191731 ],\n",
              "       [0.50170887, 0.63720137, 0.5885447 , 0.9999998 , 0.6301661 ],\n",
              "       [0.64903426, 0.893294  , 0.7191731 , 0.6301661 , 0.9999999 ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Above you will see I did add some other non-cola soda brand names in there to see what the reults might be. I found it interesting the Sprite is moresimilar to Pepsi than it is to Coke but closer to Coca-Cola than Coke (Coca-Cola is the producer of Sprite).  Pretty interesting stuff here."
      ],
      "metadata": {
        "id": "m57Q1bHbOqMC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem #5"
      ],
      "metadata": {
        "id": "5MNvQuynPYj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "text = \"data science professionals have promising career path\""
      ],
      "metadata": {
        "id": "pcZCEV2f_a_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "for word in text.split(' '):\n",
        "  words.append(word)\n",
        "\n",
        "#words = sorted(set(words))\n",
        "print(words)\n",
        "print('Total words = ', len(words))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZHWqI2n_q2U",
        "outputId": "bca59df3-9937-4637-cd40-a71f2243fbb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['data', 'science', 'professionals', 'have', 'promising', 'career', 'path']\n",
            "Total words =  7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WINDOW_SIZE = 1\n",
        "word2int = {}\n",
        "\n",
        "for i,word in enumerate(words):\n",
        "  word2int[word] = i\n",
        "\n",
        "skipNgram_data = []\n",
        "\n",
        "for idx, word in enumerate(words):\n",
        "  for neighbor in words[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(words)) + 1]:\n",
        "    if neighbor != word:\n",
        "      skipNgram_data.append([word, neighbor])\n",
        "\n",
        "skipNgram_df = pd.DataFrame(skipNgram_data, columns = ['input', 'label'])\n",
        "print(skipNgram_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtiQyCp5AqcR",
        "outputId": "ad3b60cb-7807-4a65-e5b2-04ad2efadccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            input          label\n",
            "0            data        science\n",
            "1         science           data\n",
            "2         science  professionals\n",
            "3   professionals        science\n",
            "4   professionals           have\n",
            "5            have  professionals\n",
            "6            have      promising\n",
            "7       promising           have\n",
            "8       promising         career\n",
            "9          career      promising\n",
            "10         career           path\n",
            "11           path         career\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WINDOW_SIZE = 2\n",
        "word2int = {}\n",
        "\n",
        "for i,word in enumerate(words):\n",
        "  word2int[word] = i\n",
        "\n",
        "skipNgram_data = []\n",
        "\n",
        "for idx, word in enumerate(words):\n",
        "  for neighbor in words[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(words)) + 1]:\n",
        "    if neighbor != word:\n",
        "      skipNgram_data.append([word, neighbor])\n",
        "\n",
        "skipNgram_df = pd.DataFrame(skipNgram_data, columns = ['input', 'label'])\n",
        "print(skipNgram_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGlauLYsCUlL",
        "outputId": "a933a44b-1c6f-4866-e774-8f069d1b6f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            input          label\n",
            "0            data        science\n",
            "1            data  professionals\n",
            "2         science           data\n",
            "3         science  professionals\n",
            "4         science           have\n",
            "5   professionals           data\n",
            "6   professionals        science\n",
            "7   professionals           have\n",
            "8   professionals      promising\n",
            "9            have        science\n",
            "10           have  professionals\n",
            "11           have      promising\n",
            "12           have         career\n",
            "13      promising  professionals\n",
            "14      promising           have\n",
            "15      promising         career\n",
            "16      promising           path\n",
            "17         career           have\n",
            "18         career      promising\n",
            "19         career           path\n",
            "20           path      promising\n",
            "21           path         career\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WINDOW_SIZE = 3\n",
        "word2int = {}\n",
        "\n",
        "for i,word in enumerate(words):\n",
        "  word2int[word] = i\n",
        "\n",
        "skipNgram_data = []\n",
        "\n",
        "for idx, word in enumerate(words):\n",
        "  for neighbor in words[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(words)) + 1]:\n",
        "    if neighbor != word:\n",
        "      skipNgram_data.append([word, neighbor])\n",
        "\n",
        "skipNgram_df = pd.DataFrame(skipNgram_data, columns = ['input', 'label'])\n",
        "print(skipNgram_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GiY75KtDnMG",
        "outputId": "667a09c7-0ac8-4e4f-d2cf-856dc57f337e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            input          label\n",
            "0            data        science\n",
            "1            data  professionals\n",
            "2            data           have\n",
            "3         science           data\n",
            "4         science  professionals\n",
            "5         science           have\n",
            "6         science      promising\n",
            "7   professionals           data\n",
            "8   professionals        science\n",
            "9   professionals           have\n",
            "10  professionals      promising\n",
            "11  professionals         career\n",
            "12           have           data\n",
            "13           have        science\n",
            "14           have  professionals\n",
            "15           have      promising\n",
            "16           have         career\n",
            "17           have           path\n",
            "18      promising        science\n",
            "19      promising  professionals\n",
            "20      promising           have\n",
            "21      promising         career\n",
            "22      promising           path\n",
            "23         career  professionals\n",
            "24         career           have\n",
            "25         career      promising\n",
            "26         career           path\n",
            "27           path           have\n",
            "28           path      promising\n",
            "29           path         career\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem #6"
      ],
      "metadata": {
        "id": "9iLpRqTUErEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words = []\n",
        "for word in text.split(' '):\n",
        "  words.append(word)\n",
        "\n",
        "#words = sorted(set(words))\n",
        "#print(words)\n",
        "#print('Total words = ', len(words))\n",
        "\n",
        "WINDOW_SIZE = 2\n",
        "word2int = {}\n",
        "\n",
        "#words = sorted(set(words))\n",
        "\n",
        "word_sort = sorted(set(words))\n",
        "for i,word in enumerate(word_sort):\n",
        "  word2int[word] = i\n",
        "\n",
        "\n",
        "skipNgram_data = []\n",
        "\n",
        "for idx, word in enumerate(words):\n",
        "  for neighbor in words[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(words)) + 1]:\n",
        "    if neighbor != word:\n",
        "      skipNgram_data.append([word, neighbor])\n",
        "\n",
        "skipNgram_df = pd.DataFrame(skipNgram_data, columns = ['input', 'label'])\n",
        "\n",
        "ONE_HOT_DIM = len(words)\n",
        "\n",
        "def to_one_hot_encoding(data_point_index):\n",
        "  one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
        "  one_hot_encoding[data_point_index] = 1\n",
        "  return one_hot_encoding\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for x, y in zip(skipNgram_df['input'], skipNgram_df['label']):\n",
        "  X.append(to_one_hot_encoding(word2int[x]))\n",
        "  Y.append(to_one_hot_encoding(word2int[y]))\n",
        "\n",
        "print(word2int)\n",
        "print()\n",
        "print(\"word size\", WINDOW_SIZE)\n",
        "print(\"number of entries\", len(skipNgram_df))\n",
        "print(skipNgram_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmdedhPgEqlH",
        "outputId": "256515b5-aee3-4471-d9d0-280b436280cb"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'career': 0, 'data': 1, 'have': 2, 'path': 3, 'professionals': 4, 'promising': 5, 'science': 6}\n",
            "\n",
            "word size 2\n",
            "number of entries 22\n",
            "            input          label\n",
            "0            data        science\n",
            "1            data  professionals\n",
            "2         science           data\n",
            "3         science  professionals\n",
            "4         science           have\n",
            "5   professionals           data\n",
            "6   professionals        science\n",
            "7   professionals           have\n",
            "8   professionals      promising\n",
            "9            have        science\n",
            "10           have  professionals\n",
            "11           have      promising\n",
            "12           have         career\n",
            "13      promising  professionals\n",
            "14      promising           have\n",
            "15      promising         career\n",
            "16      promising           path\n",
            "17         career           have\n",
            "18         career      promising\n",
            "19         career           path\n",
            "20           path      promising\n",
            "21           path         career\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCci4sOKGTNq",
        "outputId": "a843ee5d-0d57-4944-bd75-b82ba8a1e45f"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 1.]),\n",
              " array([0., 0., 0., 0., 0., 0., 1.]),\n",
              " array([0., 0., 0., 0., 0., 0., 1.]),\n",
              " array([0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 1., 0., 0., 0.]),\n",
              " array([0., 0., 0., 1., 0., 0., 0.])]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cn1TqPURKDaq",
        "outputId": "c1de7ea1-cfe1-4191-ead9-44ef9600d6dd"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([0., 0., 0., 0., 0., 0., 1.]),\n",
              " array([0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0.]),\n",
              " array([0., 1., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 1.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0.]),\n",
              " array([0., 0., 0., 0., 0., 0., 1.]),\n",
              " array([0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 1., 0., 0.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 1., 0., 0., 0.]),\n",
              " array([0., 0., 1., 0., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0.]),\n",
              " array([0., 0., 0., 1., 0., 0., 0.]),\n",
              " array([0., 0., 0., 0., 0., 1., 0.]),\n",
              " array([1., 0., 0., 0., 0., 0., 0.])]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    }
  ]
}